import pandas as pd

# Read the Excel file
file_path = '../data/major-industry-total-factor-productivity-klems.xlsx'
sectoral_tfp_df = pd.read_excel(file_path, header=2)


sectoral_tfp_df.head()


sectoral_tfp_df.describe()


# Import necessary libraries
import pandas as pd

# Read the Excel file
file_path = '../data/bds2022_sec.csv'
bds_sec = pd.read_csv(file_path)



bds_sec.head()


bds_sec["sector"].unique()


sectoral_tfp_df["NAICS"].unique()


sectoral_tfp_df['NAICS']


# Replace the NAICS codes in your DataFrame
sectoral_tfp_df['NAICS'] = sectoral_tfp_df['NAICS'].replace({
    'MN': '31-33',  # Manufacturing
    'DM': '33',     # Durable Manufacturing  
    'ND': '31'      # Non-durable Manufacturing
})

# Verify the changes
print("Updated NAICS codes:")
print(sectoral_tfp_df['NAICS'].unique())


# Create a new DataFrame with only two-digit NAICS codes
two_digit_sectoral_df = sectoral_tfp_df[sectoral_tfp_df['NAICS'].str.len() == 2].copy()

# Display the unique two-digit NAICS codes
print("Two-digit NAICS codes in the new DataFrame:")
print(sorted(two_digit_sectoral_df['NAICS'].unique()))

# Show the shape of the new DataFrame
print(f"\nOriginal DataFrame shape: {sectoral_tfp_df.shape}")
print(f"Two-digit NAICS DataFrame shape: {two_digit_sectoral_df.shape}")

# Display first few rows
print(f"\nFirst few rows of two_digit_naics_df:")
print(two_digit_sectoral_df.head())


sectoral_tfp_df["Measure"].unique()


# assume sectoral_tfp_df is your DataFrame with years as columns
# and its index (or a column) is the 2-digit NAICS code

# # 1) If NAICS is the index, pull it out
# filtered_df = filtered_df.reset_index().rename(columns={'index':'NAICS'})

# 2) Melt all the year-columns into a single "year" column
# Make sure filtered_df contains both TFP and Sectoral Output measures
long_df = sectoral_tfp_df.melt(
    id_vars=['NAICS', 'Industry', 'Basis', 'Measure', 'Units'], 
    var_name='year', 
    value_name='value'  # Using a generic name since we'll have both TFP and output values
)


long_df.head()


# STEP 4: Separate and process as before
tfp_long = long_df[long_df['Measure'] == 'Total factor productivity'].copy()
output_long = long_df[long_df['Measure'] == 'Sectoral output'].copy()


output_long.head()


# Calculate weights
output_pivot = output_long.pivot_table(
    values='value', 
    index='year', 
    columns='NAICS', 
    aggfunc='sum',
    fill_value=0
)

weights = (
    output_pivot.apply(lambda row: row / (row.sum() + 1e-10), axis=1)
    .stack()
    .reset_index()
    .rename(columns={0: 'weight'})
)

# Merge weights with TFP data
tfp_with_weights = tfp_long.merge(
    weights,
    on=['year', 'NAICS'],
    how='left'
).fillna({'weight': 0})


tfp_with_weights.head()


tfp_with_weights['Measure'].unique()


# import os

# # Export to CSV
# tfp_with_weights.to_csv('/Users/danielseymour/Developer/EC334-Summative/processed_data/tfp_with_weights.csv', index=False)

# print(f"Data exported to processed_data/tfp_with_weights.csv")


tfp_with_weights.head()


# Check which units are used for TFP
tfp_units = tfp_with_weights['Units'].value_counts()
print("Units used for Total factor productivity:\n", tfp_units)

# Create the pivot table with only TFP data
tfp_pivoted = tfp_with_weights.pivot(
    index=['NAICS', 'Industry', 'Basis', 'year', 'weight'],
    columns='Units',
    values='value'
).reset_index()

# Clean up column names
tfp_pivoted.columns.name = None

# Rename columns to be more code-friendly
tfp_pivoted = tfp_pivoted.rename(columns={
    'Index (2017=100)': 'tfp_index_2017',
    '% Change from previous year': 'tfp_pct_change'
})

# Display a sample of the result
print("\nFirst few rows of pivoted TFP data:")
tfp_pivoted.head()


tfp_pivoted.isna().sum()


bds_sec.head()


# make sure year is numeric
bds_sec['year'] = bds_sec['year'].astype(int)

# keep only years where we have TFP data
bds_87_on = bds_sec[bds_sec['year'] >= 1987]


tfp_pivoted.head()


# Ensure 'year' is integer in both dataframes before merging
tfp_pivoted['year'] = tfp_pivoted['year'].astype(int)

# 6) Now merge
merged = pd.merge(
    bds_87_on,
    tfp_pivoted, 
    on=['NAICS','year'],   # will give you two rows per NAICS–year (Units distinguishes them)
    how='left'
)


merged.head(20)


# Set display options to show all columns
pd.set_option('display.max_columns', None)

# Set display options to show all rows
pd.set_option('display.max_rows', None)

merged.describe()


merged.columns


# Create a new column for the percentage of firms destroyed
merged['firms_percent_destroyed'] = (merged['firmdeath_firms'] / merged['firms']) * 100


# Save the merged DataFrame to CSV in the processed_data folder
output_path = '/Users/danielseymour/Developer/EC334-Summative/processed_data/two_digit_NAICS_bds_tfp.csv'
merged.to_csv(output_path, index=False)
print(f"Data saved to {output_path}")


import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

# Set style for better looking plots
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

# 1. TIME SERIES PLOT FOR INDEX (2017=100) - Select specific industry
def plot_industry_time_series(df, naics_code=None, industry_name=None):
    """
    Plot time series for Index (2017=100) for a specific industry
    """
    fig, ax = plt.subplots(figsize=(12, 6))
    
    if naics_code:
        industry_data = df[df['NAICS'] == naics_code].copy()
        title_suffix = f"NAICS {naics_code}"
    elif industry_name:
        industry_data = df[df['Industry'].str.contains(industry_name, case=False, na=False)].copy()
        title_suffix = industry_name
    else:
        # If no specific industry selected, use first available
        naics_code = df['NAICS'].iloc[0]
        industry_data = df[df['NAICS'] == naics_code].copy()
        title_suffix = f"NAICS {naics_code}"
    
    if not industry_data.empty:
        # Sort by year for proper time series
        industry_data = industry_data.sort_values('year')
        
        # Plot the time series
        ax.plot(industry_data['year'], industry_data['Index (2017=100)'], 
                marker='o', linewidth=2.5, markersize=6)
        
        # Add horizontal line at 100 (2017 baseline)
        ax.axhline(y=100, color='red', linestyle='--', alpha=0.7, label='2017 Baseline')
        
        ax.set_title(f'Productivity Index Time Series - {title_suffix}', fontsize=14, fontweight='bold')
        ax.set_xlabel('Year', fontsize=12)
        ax.set_ylabel('Index (2017=100)', fontsize=12)
        ax.grid(True, alpha=0.3)
        ax.legend()
        
        # Add value annotations for key points
        for i, row in industry_data.iterrows():
            if row['year'] % 3 == 0:  # Annotate every 3rd year to avoid clutter
                ax.annotate(f"{row['Index (2017=100)']:.1f}", 
                           (row['year'], row['Index (2017=100)']),
                           textcoords="offset points", xytext=(0,10), ha='center')
    
    plt.tight_layout()
    return fig

# 2. MULTIPLE INDUSTRIES COMPARISON
def plot_multiple_industries_comparison(df, naics_codes=None, max_industries=5):
    """
    Compare Index (2017=100) across multiple industries
    """
    fig, ax = plt.subplots(figsize=(14, 8))
    
    if naics_codes is None:
        # Select top industries by data availability
        naics_codes = df['NAICS'].value_counts().head(max_industries).index.tolist()
    
    for naics in naics_codes:
        industry_data = df[df['NAICS'] == naics].copy().sort_values('year')
        if not industry_data.empty:
            industry_name = industry_data['Industry'].iloc[0] if 'Industry' in industry_data.columns else f"NAICS {naics}"
            ax.plot(industry_data['year'], industry_data['Index (2017=100)'], 
                   marker='o', linewidth=2, label=f"{naics}: {industry_name[:30]}...")
    
    ax.axhline(y=100, color='red', linestyle='--', alpha=0.7, label='2017 Baseline')
    ax.set_title('Productivity Index Comparison Across Industries', fontsize=14, fontweight='bold')
    ax.set_xlabel('Year', fontsize=12)
    ax.set_ylabel('Index (2017=100)', fontsize=12)
    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    return fig

# 3. DISTRIBUTION ANALYSIS
def plot_productivity_distributions(df):
    """
    Create distribution plots for key metrics
    """
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # Index distribution
    axes[0,0].hist(df['Index (2017=100)'].dropna(), bins=30, alpha=0.7, edgecolor='black')
    axes[0,0].axvline(100, color='red', linestyle='--', label='2017 Baseline')
    axes[0,0].set_title('Distribution of Productivity Index')
    axes[0,0].set_xlabel('Index (2017=100)')
    axes[0,0].legend()
    
    # Percent change distribution
    axes[0,1].hist(df['% Change from previous year'].dropna(), bins=30, alpha=0.7, edgecolor='black')
    axes[0,1].axvline(0, color='red', linestyle='--', label='No Change')
    axes[0,1].set_title('Distribution of Year-over-Year % Change')
    axes[0,1].set_xlabel('% Change from previous year')
    axes[0,1].legend()
    
    # Employment vs Index scatter
    if 'emp' in df.columns:
        scatter_data = df.dropna(subset=['emp', 'Index (2017=100)'])
        axes[1,0].scatter(scatter_data['emp'], scatter_data['Index (2017=100)'], alpha=0.6)
        axes[1,0].set_title('Employment vs Productivity Index')
        axes[1,0].set_xlabel('Employment')
        axes[1,0].set_ylabel('Index (2017=100)')
        axes[1,0].set_xscale('log')
    
    # Firms vs Index scatter
    if 'firms' in df.columns:
        scatter_data = df.dropna(subset=['firms', 'Index (2017=100)'])
        axes[1,1].scatter(scatter_data['firms'], scatter_data['Index (2017=100)'], alpha=0.6)
        axes[1,1].set_title('Number of Firms vs Productivity Index')
        axes[1,1].set_xlabel('Number of Firms')
        axes[1,1].set_ylabel('Index (2017=100)')
        axes[1,1].set_xscale('log')
    
    plt.tight_layout()
    return fig

# 4. SUMMARY STATISTICS TABLE
def create_summary_stats(df):
    """
    Create summary statistics for key variables
    """
    key_vars = ['Index (2017=100)', '% Change from previous year', 'emp', 'firms', 'estabs']
    available_vars = [var for var in key_vars if var in df.columns]
    
    summary = df[available_vars].describe()
    return summary

# USAGE EXAMPLES:
print("Available NAICS codes in your dataset:")
print(merged['NAICS'].unique())
print("\nTo create plots, use:")
print("1. plot_industry_time_series(merged, naics_code='21')  # for specific NAICS")
print("2. plot_multiple_industries_comparison(merged, naics_codes=['21', '22', '23'])")
print("3. plot_productivity_distributions(merged)")
print("4. summary_stats = create_summary_stats(merged)")

# Example: Plot first available industry
if not merged.empty:
    first_naics = merged['NAICS'].iloc[0]
    fig1 = plot_industry_time_series(merged, naics_code=first_naics)
    plt.show()
    
    # Show summary statistics
    print("\nSummary Statistics:")
    print(create_summary_stats(merged))


plot_productivity_distributions(merged)



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
import statsmodels.api as sm
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# Set plotting style
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

def create_moving_averages(df, window=3):
    """
    Create 3-year moving averages for job dynamics variables
    """
    # Job dynamics variables to smooth
    job_vars = [
        'job_creation', 'job_creation_rate', 'job_creation_births', 'job_creation_continuers',
        'job_destruction', 'job_destruction_rate', 'job_destruction_deaths', 'job_destruction_continuers',
        'net_job_creation', 'net_job_creation_rate', 'reallocation_rate',
        'estabs_entry', 'estabs_entry_rate', 'estabs_exit', 'estabs_exit_rate',
        '% Change from previous year', 'Index (2017=100)'
    ]
    
    # Only include variables that exist in the dataframe
    available_vars = [var for var in job_vars if var in df.columns]
    
    # Create moving averages by NAICS code
    df_ma = df.copy()
    
    for naics in df['NAICS'].unique():
        mask = df['NAICS'] == naics
        naics_data = df[mask].sort_values('year')
        
        for var in available_vars:
            if var in naics_data.columns:
                # Calculate 3-year moving average
                ma_values = naics_data[var].rolling(window=window, center=True, min_periods=1).mean()
                df_ma.loc[mask, f'{var}_MA3'] = ma_values.values
    
    return df_ma

def run_productivity_job_regressions(df_ma):
    """
    Run various regressions relating job dynamics to productivity
    """
    results = {}
    
    # Define regression specifications
    regressions = {
        'Net Job Creation Impact': {
            'y': 'Index (2017=100)_MA3',
            'x': ['net_job_creation_rate_MA3', 'reallocation_rate_MA3']
        },
        'Job Creation vs Destruction': {
            'y': '% Change from previous year_MA3',
            'x': ['job_creation_rate_MA3', 'job_destruction_rate_MA3']
        },
        'Entry vs Exit Effects': {
            'y': 'Index (2017=100)_MA3',
            'x': ['estabs_entry_rate_MA3', 'estabs_exit_rate_MA3', 'net_job_creation_rate_MA3']
        },
        'Birth vs Continuing Establishments': {
            'y': '% Change from previous year_MA3',
            'x': ['job_creation_rate_births_MA3', 'job_creation_continuers_MA3', 'job_destruction_rate_MA3']
        }
    }
    
    for reg_name, spec in regressions.items():
        print(f"\n{'='*60}")
        print(f"REGRESSION: {reg_name}")
        print(f"{'='*60}")
        
        # Check if all variables exist
        all_vars = [spec['y']] + spec['x']
        available_vars = [var for var in all_vars if var in df_ma.columns]
        
        if len(available_vars) == len(all_vars):
            # Create regression dataset
            reg_data = df_ma[available_vars + ['NAICS', 'year']].dropna()
            
            if len(reg_data) > 10:  # Ensure sufficient observations
                y = reg_data[spec['y']]
                X = reg_data[spec['x']]
                
                # Add constant for intercept
                X_with_const = sm.add_constant(X)
                
                # Run regression
                model = sm.OLS(y, X_with_const).fit()
                results[reg_name] = {
                    'model': model,
                    'data': reg_data,
                    'r_squared': model.rsquared,
                    'adj_r_squared': model.rsquared_adj,
                    'n_obs': len(reg_data)
                }
                
                # Print results
                print(f"Observations: {len(reg_data)}")
                print(f"R-squared: {model.rsquared:.4f}")
                print(f"Adj. R-squared: {model.rsquared_adj:.4f}")
                print(f"F-statistic p-value: {model.f_pvalue:.4f}")
                print("\nCoefficients:")
                print(model.summary().tables[1])
                
            else:
                print(f"Insufficient data ({len(reg_data)} observations)")
        else:
            missing_vars = [var for var in all_vars if var not in df_ma.columns]
            print(f"Missing variables: {missing_vars}")
    
    return results

def plot_regression_diagnostics(results):
    """
    Create diagnostic plots for regression results
    """
    n_regressions = len(results)
    if n_regressions == 0:
        return
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    axes = axes.flatten()
    
    for i, (reg_name, result) in enumerate(results.items()):
        if i >= 4:  # Only plot first 4 regressions
            break
            
        model = result['model']
        reg_data = result['data']
        
        # Residuals vs Fitted
        fitted_values = model.fittedvalues
        residuals = model.resid
        
        axes[i].scatter(fitted_values, residuals, alpha=0.6)
        axes[i].axhline(y=0, color='red', linestyle='--')
        axes[i].set_xlabel('Fitted Values')
        axes[i].set_ylabel('Residuals')
        axes[i].set_title(f'{reg_name}\nResiduals vs Fitted (R² = {result["r_squared"]:.3f})')
        axes[i].grid(True, alpha=0.3)
    
    plt.tight_layout()
    return fig

def industry_specific_analysis(df_ma, naics_codes=None):
    """
    Run regressions for specific industries
    """
    if naics_codes is None:
        # Use top 5 industries by data availability
        naics_codes = df_ma['NAICS'].value_counts().head(5).index.tolist()
    
    industry_results = {}
    
    for naics in naics_codes:
        print(f"\n{'='*50}")
        print(f"INDUSTRY ANALYSIS: NAICS {naics}")
        print(f"{'='*50}")
        
        industry_data = df_ma[df_ma['NAICS'] == naics].copy()
        
        if len(industry_data) >= 5:  # Need minimum observations
            # Simple regression: Net job creation rate vs productivity change
            if all(col in industry_data.columns for col in ['% Change from previous year_MA3', 'net_job_creation_rate_MA3']):
                y = industry_data['% Change from previous year_MA3'].dropna()
                x = industry_data['net_job_creation_rate_MA3'].dropna()
                
                # Align the data
                common_index = y.index.intersection(x.index)
                if len(common_index) >= 3:
                    y_aligned = y.loc[common_index]
                    x_aligned = x.loc[common_index]
                    
                    # Run regression
                    X_with_const = sm.add_constant(x_aligned)
                    model = sm.OLS(y_aligned, X_with_const).fit()
                    
                    industry_results[naics] = {
                        'model': model,
                        'r_squared': model.rsquared,
                        'coefficient': model.params.iloc[-1],
                        'p_value': model.pvalues.iloc[-1]
                    }
                    
                    print(f"Net Job Creation Rate → Productivity Change")
                    print(f"Coefficient: {model.params.iloc[-1]:.4f}")
                    print(f"P-value: {model.pvalues.iloc[-1]:.4f}")
                    print(f"R-squared: {model.rsquared:.4f}")
                else:
                    print("Insufficient aligned data")
            else:
                print("Required variables not available")
        else:
            print(f"Insufficient data ({len(industry_data)} observations)")
    
    return industry_results

def plot_job_dynamics_trends(df_ma, naics_codes=None):
    """
    Plot job creation/destruction trends with moving averages
    """
    if naics_codes is None:
        naics_codes = df_ma['NAICS'].value_counts().head(4).index.tolist()
    
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    axes = axes.flatten()
    
    for i, naics in enumerate(naics_codes):
        if i >= 4:
            break
            
        industry_data = df_ma[df_ma['NAICS'] == naics].sort_values('year')
        
        if not industry_data.empty and 'job_creation_rate_MA3' in df_ma.columns:
            # Plot job creation and destruction rates
            axes[i].plot(industry_data['year'], industry_data['job_creation_rate_MA3'], 
                        label='Job Creation Rate (3Y MA)', marker='o', linewidth=2)
            
            if 'job_destruction_rate_MA3' in df_ma.columns:
                axes[i].plot(industry_data['year'], industry_data['job_destruction_rate_MA3'], 
                            label='Job Destruction Rate (3Y MA)', marker='s', linewidth=2)
            
            if 'net_job_creation_rate_MA3' in df_ma.columns:
                axes[i].plot(industry_data['year'], industry_data['net_job_creation_rate_MA3'], 
                            label='Net Job Creation Rate (3Y MA)', marker='^', linewidth=2)
            
            axes[i].set_title(f'NAICS {naics}: Job Dynamics (3-Year MA)')
            axes[i].set_xlabel('Year')
            axes[i].set_ylabel('Rate')
            axes[i].legend()
            axes[i].grid(True, alpha=0.3)
    
    plt.tight_layout()
    return fig

# MAIN EXECUTION
def run_complete_analysis(df):
    """
    Run the complete job dynamics regression analysis
    """
    print("Creating 3-year moving averages...")
    df_ma = create_moving_averages(df)
    
    print(f"Created moving averages for {len([col for col in df_ma.columns if '_MA3' in col])} variables")
    
    # Run pooled regressions
    print("\n" + "="*80)
    print("POOLED REGRESSION ANALYSIS")
    print("="*80)
    regression_results = run_productivity_job_regressions(df_ma)
    
    # Industry-specific analysis
    print("\n" + "="*80)
    print("INDUSTRY-SPECIFIC ANALYSIS")
    print("="*80)
    industry_results = industry_specific_analysis(df_ma)
    
    # Create plots
    if regression_results:
        fig1 = plot_regression_diagnostics(regression_results)
        plt.show()
    
    fig2 = plot_job_dynamics_trends(df_ma)
    plt.show()
    
    return df_ma, regression_results, industry_results

# Usage
print("Starting job dynamics regression analysis...")
print("Call: df_ma, reg_results, ind_results = run_complete_analysis(merged)")


df_ma, regression_results, industry_results = run_complete_analysis(merged)



import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Set plotting style
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

def create_simple_moving_averages(df, variables, window=3):
    """
    Create 3-year moving averages for specified variables
    """
    df_ma = df.copy()
    
    # Sort by NAICS and year for proper time series
    df_ma = df_ma.sort_values(['NAICS', 'year'])
    
    for naics in df['NAICS'].unique():
        mask = df_ma['NAICS'] == naics
        
        for var in variables:
            if var in df_ma.columns:
                # Calculate 3-year moving average for this industry
                ma_values = df_ma.loc[mask, var].rolling(window=window, center=True, min_periods=1).mean()
                df_ma.loc[mask, f'{var}_MA3'] = ma_values
    
    return df_ma

def plot_job_creation_ma(df_ma, naics_codes=None, max_industries=6):
    """
    Plot job creation with 3-year moving average
    """
    if naics_codes is None:
        # Get top industries by data availability
        naics_codes = df_ma['NAICS'].value_counts().head(max_industries).index.tolist()
    
    n_industries = len(naics_codes)
    n_cols = 3
    n_rows = (n_industries + n_cols - 1) // n_cols
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 6*n_rows))
    if n_rows == 1:
        axes = [axes] if n_industries == 1 else axes
    else:
        axes = axes.flatten()
    
    for i, naics in enumerate(naics_codes):
        industry_data = df_ma[df_ma['NAICS'] == naics].sort_values('year')
        
        if not industry_data.empty and 'job_creation' in industry_data.columns:
            ax = axes[i] if n_industries > 1 else axes
            
            # Plot original data
            ax.plot(industry_data['year'], industry_data['job_creation'], 
                   alpha=0.3, color='lightblue', linewidth=1, label='Original')
            
            # Plot moving average
            if 'job_creation_MA3' in industry_data.columns:
                ax.plot(industry_data['year'], industry_data['job_creation_MA3'], 
                       color='darkblue', linewidth=3, marker='o', markersize=4, 
                       label='3-Year Moving Average')
            
            # Get industry name if available
            industry_name = industry_data['Industry'].iloc[0] if 'Industry' in industry_data.columns else f"NAICS {naics}"
            ax.set_title(f'{naics}: {industry_name[:40]}', fontsize=12, fontweight='bold')
            ax.set_xlabel('Year')
            ax.set_ylabel('Job Creation')
            ax.legend()
            ax.grid(True, alpha=0.3)
    
    # Hide empty subplots
    if n_industries < len(axes):
        for i in range(n_industries, len(axes)):
            axes[i].set_visible(False)
    
    plt.tight_layout()
    plt.suptitle('Job Creation: Original vs 3-Year Moving Average', fontsize=16, y=1.02)
    return fig

def plot_single_variable_comparison(df_ma, variable, naics_codes=None, max_industries=6):
    """
    Plot any variable with its moving average for comparison
    """
    if naics_codes is None:
        naics_codes = df_ma['NAICS'].value_counts().head(max_industries).index.tolist()
    
    n_industries = len(naics_codes)
    n_cols = 2
    n_rows = (n_industries + n_cols - 1) // n_cols
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 5*n_rows))
    if n_rows == 1:
        axes = [axes] if n_industries == 1 else axes
    else:
        axes = axes.flatten()
    
    for i, naics in enumerate(naics_codes):
        industry_data = df_ma[df_ma['NAICS'] == naics].sort_values('year')
        
        if not industry_data.empty and variable in industry_data.columns:
            ax = axes[i] if n_industries > 1 else axes
            
            # Plot original data
            ax.plot(industry_data['year'], industry_data[variable], 
                   alpha=0.4, color='gray', linewidth=1, label='Original', marker='.')
            
            # Plot moving average
            ma_var = f'{variable}_MA3'
            if ma_var in industry_data.columns:
                ax.plot(industry_data['year'], industry_data[ma_var], 
                       color='red', linewidth=3, marker='o', markersize=5, 
                       label='3-Year Moving Average')
            
            # Get industry name
            industry_name = industry_data['Industry'].iloc[0] if 'Industry' in industry_data.columns else f"NAICS {naics}"
            ax.set_title(f'{naics}: {industry_name[:30]}', fontsize=11, fontweight='bold')
            ax.set_xlabel('Year')
            ax.set_ylabel(variable.replace('_', ' ').title())
            ax.legend()
            ax.grid(True, alpha=0.3)
    
    # Hide empty subplots
    if n_industries < len(axes):
        for i in range(n_industries, len(axes)):
            axes[i].set_visible(False)
    
    plt.tight_layout()
    plt.suptitle(f'{variable.replace("_", " ").title()}: Original vs 3-Year Moving Average', 
                 fontsize=14, y=1.02)
    return fig

# Simple usage functions
def create_and_plot_job_creation(df):
    """
    Simple function to create moving averages and plot job creation
    """
    print("Creating 3-year moving averages for job creation...")
    
    # Create moving averages for job-related variables
    job_variables = ['job_creation', 'job_creation_rate', 'job_destruction', 
                     'job_destruction_rate', 'net_job_creation', 'net_job_creation_rate']
    
    # Only use variables that exist in the dataframe
    available_vars = [var for var in job_variables if var in df.columns]
    print(f"Found these job variables: {available_vars}")
    
    df_ma = create_simple_moving_averages(df, available_vars)
    
    # Plot job creation
    fig = plot_job_creation_ma(df_ma)
    plt.show()
    
    return df_ma

def plot_specific_variable(df_ma, variable_name):
    """
    Plot a specific variable with its moving average
    """
    if variable_name in df_ma.columns:
        fig = plot_single_variable_comparison(df_ma, variable_name)
        plt.show()
    else:
        print(f"Variable '{variable_name}' not found in dataframe")
        print(f"Available variables: {list(df_ma.columns)}")

# Usage examples:
print("To create moving averages and plot job creation:")
print("df_with_ma = create_and_plot_job_creation(merged)")
print()
print("To plot a specific variable:")
print("plot_specific_variable(df_with_ma, 'job_creation_rate')")
print("plot_specific_variable(df_with_ma, 'net_job_creation')")
print("plot_specific_variable(df_with_ma, 'estabs_entry_rate')")


# Just create moving averages without plotting
job_variables = ['job_creation', 'job_creation_rate', 'net_job_creation']
df_with_ma = create_simple_moving_averages(merged, job_variables)

# Then plot whatever you want
plot_specific_variable(df_with_ma, 'job_creation')
